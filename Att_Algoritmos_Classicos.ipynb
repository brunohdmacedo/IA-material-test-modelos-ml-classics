{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R5ieXXL-C8Y",
        "outputId": "76e7f70d-c124-4b21-8904-abcc60283158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OBYQFjS6gjp",
        "outputId": "e30032a5-3043-41ff-9eb8-dbd212234c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.0\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-24.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-24.7.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-24.7.0 scikit-optimize-0.10.2\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.22.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.13.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "#Install\n",
        "!pip install catboost\n",
        "!pip install xlsxwriter\n",
        "!pip install catboost\n",
        "!pip install scikit-optimize\n",
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jfPcmI79eIT",
        "outputId": "41671e8c-2955-48ca-a191-855a49d8c5cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import *\n",
        "from threading import Thread\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from csv import writer\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from concurrent.futures import as_completed\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import csv\n",
        "import time\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IVHUIdV3gaz",
        "outputId": "1083ed95-13f5-46ff-b022-1c465a7dc5ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "                                   \n",
            "^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^\n",
            "                                   \n",
            "Data shape: (5292, 1570)\n",
            "Labels shape: (5292,)\n",
            "Class names: ['Actinolite' 'Adamite' 'Aegirine' 'Aenigmatite' 'Akermanite' 'Albite'\n",
            " 'Almandine' 'Amblygonite' 'Amesite' 'Analcime' 'Anatase' 'Andalusite'\n",
            " 'Andradite' 'Anglesite' 'Anhydrite' 'Ankerite' 'Annite' 'Anorthite'\n",
            " 'Aragonite' 'Arfvedsonite' 'Arsenopyrite' 'Astrophyllite' 'Atacamite'\n",
            " 'Augelite' 'Augite' 'AxiniteFe' 'Azurite' 'Baddeleyite' 'Barrerite'\n",
            " 'Barysilite' 'Baryte' 'Bertrandite' 'Beryl' 'Beudantite' 'Bikitaite'\n",
            " 'Bobdownsite' 'Braunite' 'Brazilianite' 'Brookite' 'Brucite' 'Bustamite'\n",
            " 'Calcite' 'Cassiterite' 'Catapleiite' 'Celestine' 'Cerussite'\n",
            " 'ChabaziteCa' 'Chloritoid' 'Chondrodite' 'Chrysoberyl' 'Clinochlore'\n",
            " 'Clinohumite' 'ClinoptiloliteCa' 'Clinozoisite' 'ColumbiteFe'\n",
            " 'Conichalcite' 'Cordierite' 'Corundum' 'Covellite' 'Creedite' 'Crocoite'\n",
            " 'Cuprite' 'Danburite' 'Datolite' 'Diamond' 'Diaspore' 'Diopside'\n",
            " 'Dioptase' 'Dolomite' 'Dravite' 'Edenite' 'Edingtonite' 'Elbaite'\n",
            " 'Enstatite' 'Eosphorite' 'Epididymite' 'Epidote' 'Erythrite' 'Euclase'\n",
            " 'Eudialyte' 'Fayalite' 'Ferberite' 'Fluorapatite' 'FluorapophylliteK'\n",
            " 'Fluorcalciomicrolite' 'Fluorite' 'Fluorophlogopite' 'Fluororichterite'\n",
            " 'Fluoruvite' 'Forsterite' 'Gaylussite' 'Gehlenite' 'GmeliniteNa'\n",
            " 'Grossular' 'Grunerite' 'Gypsum' 'Hausmannite' 'Hauyne' 'Hedenbergite'\n",
            " 'Hemimorphite' 'HeulanditeCa' 'Hubnerite' 'Humite' 'Hydroxylherderite'\n",
            " 'Ilvaite' 'Inderite' 'Inyoite' 'Jadeite' 'Kanoite' 'Kornerupine'\n",
            " 'Kurnakovite' 'Kyanite' 'Laumontite' 'Laverovite' 'Lawsonite' 'Lazulite'\n",
            " 'Legrandite' 'Leucophanite' 'Ludlamite' 'Magnesiohastingsite' 'Magnesite'\n",
            " 'Marialite' 'Mesolite' 'Metatorbernite' 'Microcline' 'Mimetite'\n",
            " 'MonaziteCe' 'Montebrasite' 'Monticellite' 'Muscovite' 'Natrolite'\n",
            " 'Nepheline' 'Olivenite' 'Olmiite' 'Opal' 'Orthoclase' 'Paravauxite'\n",
            " 'Pectolite' 'Pharmacosiderite' 'Phenakite' 'PhillipsiteCa'\n",
            " 'Polylithionite' 'Prehnite' 'Pyrite' 'Pyromorphite' 'Pyrope'\n",
            " 'PyrosmaliteFe' 'Quartz' 'Rhodochrosite' 'Rhodonite' 'Riebeckite'\n",
            " 'Rutile' 'Sanbornite' 'Scheelite' 'Scholzite' 'Scolecite' 'Senegalite'\n",
            " 'Serandite' 'Shortite' 'Siderite' 'Smithsonite' 'Sodalite' 'Spessartine'\n",
            " 'Sphalerite' 'Spinel' 'Spodumene' 'Staurolite' 'Stellerite' 'Stibnite'\n",
            " 'StilbiteCa' 'Strontianite' 'Sulphur' 'Talc' 'ThomsoniteCa' 'Tilleyite'\n",
            " 'Titanite' 'Topaz' 'Tourmaline' 'Tremolite' 'Trilithionite' 'Triphylite'\n",
            " 'Triplite' 'Vanadinite' 'Vayrynenite' 'Vesuvianite' 'Vivianite'\n",
            " 'Wavellite' 'Whewellite' 'Witherite' 'Wulfenite' 'Zircon' 'Zoisite']\n",
            "                                   \n",
            "^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^\n",
            "                                   \n"
          ]
        }
      ],
      "source": [
        "def load_spectrum_file(dir_path, max_subfolders=None, max_files_per_subdir=None, max_rows=None):\n",
        "    \"\"\"Carrega arquivos de espectro e associa rótulos numéricos às subpastas.\"\"\"\n",
        "    data, labels = [], []\n",
        "    subfolder_labels = {}\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    # Contadores para controlar a quantidade de subpastas e arquivos lidos\n",
        "    subfolder_count = 0\n",
        "\n",
        "    for root, dirs, files in os.walk(dir_path):\n",
        "        # Limitar a quantidade de subpastas\n",
        "        if max_subfolders is not None and subfolder_count >= max_subfolders:\n",
        "            break\n",
        "\n",
        "        for dir_name in dirs:\n",
        "            subfolder_path = os.path.join(root, dir_name)\n",
        "            subfolder_labels[subfolder_path] = dir_name\n",
        "            subfolder_count += 1\n",
        "\n",
        "            # Limitar a quantidade de subpastas\n",
        "            if max_subfolders is not None and subfolder_count > max_subfolders:\n",
        "                break\n",
        "\n",
        "            file_count = 0\n",
        "            for filename in os.listdir(subfolder_path):\n",
        "                if filename.endswith('.csv'):\n",
        "                    if max_files_per_subdir is not None and file_count >= max_files_per_subdir:\n",
        "                        break\n",
        "                    file_path = os.path.join(subfolder_path, filename)\n",
        "                    try:\n",
        "                        df = pd.read_csv(file_path, delimiter=',', nrows=max_rows)\n",
        "                        y = df.iloc[:, 1].values  # Pega os valores da segunda coluna\n",
        "\n",
        "                        # Adiciona o rótulo da subpasta à lista de labels\n",
        "                        labels.append(subfolder_labels[subfolder_path])\n",
        "                        data.append(y)\n",
        "                        file_count += 1\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error reading file {file_path}: {e}\")\n",
        "\n",
        "    # Transforma os rótulos das subpastas em números\n",
        "    labels = label_encoder.fit_transform(labels)\n",
        "    return np.array(data), np.array(labels), label_encoder.classes_\n",
        "\n",
        "# Exemplo de uso\n",
        "print(\"Loading data...\")\n",
        "data, labels, class_names = load_spectrum_file(\n",
        "    '/content/drive/MyDrive/Iniciação Científica 2023-2024/PQ_TCC_IC/Raman/Data_csv/',\n",
        "    max_subfolders=None,\n",
        "    max_files_per_subdir=None,\n",
        "    max_rows=None\n",
        ")\n",
        "print(\"                                   \")\n",
        "print(\"^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^\")\n",
        "print(\"                                   \")\n",
        "print(f\"Data shape: {data.shape}\")\n",
        "print(f\"Labels shape: {labels.shape}\")\n",
        "print(f\"Class names: {class_names}\")\n",
        "print(\"                                   \")\n",
        "print(\"^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^\")\n",
        "print(\"                                   \")\n",
        "\n",
        "X_=data\n",
        "y=labels\n",
        "\n",
        "#train_data, test_data, train_label, test_label = train_test_split(data, labels, test_size=30, train_size=70, random_state=1, shuffle=True, stratify=True)\n",
        "#print(f\"Train data shape: {train_data.shape}, Train label shape: {train_label.shape}\")\n",
        "#print(f\"Test data shape: {test_data.shape}, Test label shape: {test_label.shape}\")\n",
        "#print(\"                                   \")\n",
        "#print(\"^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^\")\n",
        "#rint(\"                                   \")\n",
        "#X_train = train_data\n",
        "#y_train = train_label\n",
        "#X_test = test_data\n",
        "#y_test = test_label\n",
        "\n",
        "#print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "#print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
        "#print(\"                                   \")\n",
        "#print(\"^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^ ^¬^\")\n",
        "#print(\"                                   \")\n",
        "#print(\"Completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MF7YPesdcrb",
        "outputId": "f3112b76-a18a-4666-eab8-55a8902b0027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  3  3  3  3  3  3  3  3\n",
            "  3  3  3  3  3  3  3  3  3  3  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
            "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
            "  2  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
            "  1  1  1  1  8  8  8  8  8  8  8  8  8  8  7  7  7  7  7  7  7  7  7  7\n",
            "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  5  5  5  5  5  5  5  5  5  5\n",
            "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
            "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
            "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
            "  5  5  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
            "  9  9  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
            " 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
            " 12 12 12 12 12 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18\n",
            " 18 18 18 18 18 18 18 18 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
            " 13 13 13 13 13 13 13 13 13 13 13 13 13 13 17 17 17 17 17 17 17 17 17 17\n",
            " 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
            " 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 10 10\n",
            " 10 10 10 10 10 10 10 10 10 10 10 10 15 15 15 15 15 15 15 15 15 15 15 15\n",
            " 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
            " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
            " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
            " 11 11 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
            " 14 14 14 14 19 19 19 19 19 19 19 19 19 19 19 19 19 19 22 22 22 22 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 20 20 20 20 20 20 20 20 20 20\n",
            " 20 20 20 20 24 24 24 24 24 24 24 24 24 24 24 24 21 21 21 21 21 21 21 21\n",
            " 21 21 21 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
            " 23 23 23 23 23]\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24]\n",
            "['Actinolite' 'Adamite' 'Aegirine' 'Aenigmatite' 'Akermanite' 'Albite'\n",
            " 'Almandine' 'Amblygonite' 'Amesite' 'Analcime' 'Anatase' 'Andalusite'\n",
            " 'Andradite' 'Anglesite' 'Anhydrite' 'Ankerite' 'Annite' 'Anorthite'\n",
            " 'Aragonite' 'Arfvedsonite' 'Arsenopyrite' 'Atacamite' 'AxiniteFe'\n",
            " 'Azurite' 'Barrerite']\n"
          ]
        }
      ],
      "source": [
        "print(labels)\n",
        "print(np.unique(labels))\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMI3x1iBvPWL"
      },
      "outputs": [],
      "source": [
        "def experiment(model_name, model, params, X_train, y_train, X_test, y_test, i):\n",
        "    data_path = '/content/drive/MyDrive/Iniciação Científica 2023-2024/PQ_TCC_IC/Raman/Results/Clássicos/'\n",
        "    # Configure the cross-validation procedure\n",
        "    cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "\n",
        "    # Define search\n",
        "    search = BayesSearchCV(model, params, scoring='accuracy', cv=cv_inner, n_iter=5, refit=True, random_state=1, n_jobs=1)\n",
        "\n",
        "    # Execute search\n",
        "    result = search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best performing model fit on the whole training set\n",
        "    best_model = result.best_estimator_\n",
        "\n",
        "    # Evaluate model on the hold out dataset\n",
        "    yhat = best_model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    acc = accuracy_score(y_test, yhat)\n",
        "    prec = precision_score(y_test, yhat, average='weighted')\n",
        "    rec = recall_score(y_test, yhat, average='weighted')\n",
        "    f1 = f1_score(y_test, yhat, average='weighted')\n",
        "    mcc = matthews_corrcoef(y_test, yhat)\n",
        "\n",
        "    # Store the result\n",
        "    results = [model_name, i, acc, rec, prec, f1, mcc, result.best_score_, result.best_params_]\n",
        "\n",
        "    # Write the results to a CSV file in the specified directory\n",
        "    results_file = f\"{data_path}{model_name}_results.csv\"\n",
        "    with open(results_file, 'a', newline='') as f_object:\n",
        "        writer_object = csv.writer(f_object)\n",
        "        writer_object.writerow(results)\n",
        "\n",
        "    # Report progress\n",
        "    print(f\"{model_name} {i} > acc={acc:.2f}, est={result.best_score_:.2f}, cfg={result.best_params_}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition of the experiment\n",
        "def experiment(model_name, model, params, X_, y):\n",
        "    # Caminho da pasta para salvar o arquivo\n",
        "    data_path = '/content/drive/MyDrive/Iniciação Científica 2023-2024/PQ_TCC_IC/Raman/Results/Clássicos/SIEPE/'\n",
        "\n",
        "    # Nome do arquivo para salvar os resultados\n",
        "    results_file = os.path.join(data_path, model_name + '.xlsx')\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Configure o train_test_split fora do loop\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_, y, test_size=0.3, random_state=1, stratify=y)\n",
        "\n",
        "    # configure the cross-validation procedure para o treinamento\n",
        "    cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "\n",
        "    # define search\n",
        "    search = BayesSearchCV(model, params, scoring='accuracy', cv=cv_inner, n_iter=10, refit=True, random_state=1, n_jobs=-1)\n",
        "\n",
        "    # execute search\n",
        "    result = search.fit(X_train, y_train)\n",
        "\n",
        "    # get the best performing model fit on the whole training set\n",
        "    best_model = result.best_estimator_\n",
        "\n",
        "    # evaluate model on the hold out dataset\n",
        "    yhat = best_model.predict(X_test)\n",
        "\n",
        "    # evaluate the model\n",
        "    acc = accuracy_score(y_test, yhat)\n",
        "    prec = precision_score(y_test, yhat, average='weighted', zero_division=1)\n",
        "    rec = recall_score(y_test, yhat, average='weighted')\n",
        "    f1 = f1_score(y_test, yhat, average='weighted')\n",
        "    mcc = matthews_corrcoef(y_test, yhat)\n",
        "\n",
        "    # store the result\n",
        "    results.append([model_name, acc, rec, prec, f1, result.best_score_, result.best_params_])\n",
        "\n",
        "    # report progress\n",
        "    print(f\"{model_name} > acc={acc:.3f}, est={result.best_score_:.3f}, cfg={result.best_params_}\")\n",
        "\n",
        "    # summarize the estimated performance of the model\n",
        "    mean_acc = sum(r[1] for r in results) / len(results)\n",
        "    mean_rec = sum(r[2] for r in results) / len(results)\n",
        "    mean_prec = sum(r[3] for r in results) / len(results)\n",
        "    mean_f1 = sum(r[4] for r in results) / len(results)\n",
        "\n",
        "    # save results to file\n",
        "    df = pd.DataFrame(results, columns=['model', 'acc', 'rec', 'prec', 'f1', 'best_score', 'best_params'])\n",
        "    df.to_excel(results_file, index=False)"
      ],
      "metadata": {
        "id": "Rmjk8FdrraUu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sk6gsx945YZK"
      },
      "outputs": [],
      "source": [
        "# Definição dos modelos e parâmetros\n",
        "model_params = {\n",
        "    'lr': {'model': LogisticRegression(),\n",
        "           'params': {\n",
        "               'C': Real(1e-4, 1e4, prior='log-uniform'),\n",
        "               'fit_intercept': Categorical([True, False]),\n",
        "               'solver': Categorical(['newton-cg', 'liblinear', 'saga'])}},  # Removido 'sag'\n",
        "\n",
        "#    'knn': {'model': KNeighborsClassifier(),\n",
        "#            'params': {\n",
        "#                'n_neighbors': Integer(1, 50),\n",
        "#                'weights': Categorical(['uniform', 'distance']),\n",
        "#                'algorithm': Categorical(['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
        "#                'p': Integer(1, 5)}},\n",
        "#\n",
        "    'nb': {'model': GaussianNB(),\n",
        "           'params': {\n",
        "               'var_smoothing': Real(1e-10, 1e-1, prior='log-uniform')}},\n",
        "\n",
        "    'dt': {'model': DecisionTreeClassifier(),\n",
        "           'params': {\n",
        "               'criterion': Categorical(['gini', 'entropy']),\n",
        "               'splitter': Categorical(['best', 'random']),\n",
        "               'max_depth': Integer(3, 30),\n",
        "               'min_samples_split': Integer(2, 10),\n",
        "               'min_samples_leaf': Integer(1, 10),\n",
        "               'max_features': Real(0.1, 1.0, prior='uniform')}},\n",
        "\n",
        "#    'svm': {'model': LinearSVC(),\n",
        "#            'params': {\n",
        "#                'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
        "#                'loss': Categorical(['hinge', 'squared_hinge']),\n",
        "#                'tol': Real(1e-6, 1e-2, prior='log-uniform')}},\n",
        "#\n",
        "#    'gpc': {'model': GaussianProcessClassifier(),\n",
        "#            'params': {\n",
        "#                'optimizer': Categorical(['fmin_l_bfgs_b', None]),\n",
        "#                'n_restarts_optimizer': Integer(0, 10),\n",
        "#                'max_iter_predict': Integer(100, 1000)}},\n",
        "\n",
        "#    'mlp': {'model': MLPClassifier(),\n",
        "#            'params': {\n",
        "#                'hidden_layer_sizes': Integer(10, 100),\n",
        "#                'activation': Categorical(['identity', 'logistic', 'tanh', 'relu']),\n",
        "#                'solver': Categorical(['sgd', 'adam']),\n",
        "#                'alpha': Real(1e-5, 1e-1, prior='log-uniform'),\n",
        "#                'learning_rate': Categorical(['constant', 'invscaling', 'adaptive']),\n",
        "#                'learning_rate_init': Real(1e-4, 1e-1, prior='log-uniform'),\n",
        "#                'max_iter': Integer(1000, 1001)}},\n",
        "\n",
        "#    'ridge': {'model': RidgeClassifier(),\n",
        "#              'params': {\n",
        "#                  'alpha': Real(1e-4, 1e4, prior='log-uniform'),\n",
        "#                  'fit_intercept': Categorical([True, False]),\n",
        "#                  'solver': Categorical(['auto', 'cholesky', 'lsqr', 'sparse_cg', 'saga'])}},  # Removido 'sag'\n",
        "\n",
        "    'rf': {'model': RandomForestClassifier(),\n",
        "           'params': {\n",
        "               'n_estimators': Integer(10, 500),\n",
        "               'criterion': Categorical(['gini', 'entropy']),\n",
        "               'max_depth': Integer(3, 30),\n",
        "               'min_samples_split': Integer(2, 10),\n",
        "               'min_samples_leaf': Integer(1, 10),\n",
        "               'max_features': Real(0.1, 1.0, prior='uniform'),\n",
        "               'bootstrap': Categorical([True, False]),\n",
        "               'class_weight': Categorical(['balanced', 'balanced_subsample', None])}},\n",
        "\n",
        "#    'qda': {'model': QuadraticDiscriminantAnalysis(),\n",
        "#            'params': {\n",
        "#                'reg_param': Real(0, 1, prior='uniform'),\n",
        "#                'store_covariance': Categorical([True, False]),\n",
        "#                'tol': Real(1e-5, 1e-1, prior='log-uniform')}},\n",
        "\n",
        "#    'ada': {'model': AdaBoostClassifier(),\n",
        "#            'params': {\n",
        "#                'n_estimators': Integer(10, 500),\n",
        "#                'learning_rate': Real(1e-3, 1, prior='log-uniform'),\n",
        "#                'algorithm': Categorical(['SAMME', 'SAMME.R'])}},\n",
        "\n",
        "#    'gbc': {'model': GradientBoostingClassifier(),\n",
        "#            'params': {\n",
        "#                'n_estimators': Integer(10, 500),\n",
        "#                'learning_rate': Real(1e-3, 1, prior='log-uniform'),\n",
        "#                'max_depth': Integer(3, 10),\n",
        "#                'min_samples_split': Integer(2, 10),\n",
        "#                'min_samples_leaf': Integer(1, 10),\n",
        "#                'max_features': Real(0.1, 1.0, prior='uniform'),\n",
        "#                'subsample': Real(0.1, 1.0, prior='uniform')}},\n",
        "\n",
        "#    'lda': {'model': LinearDiscriminantAnalysis(),\n",
        "#            'params': {\n",
        "#                'solver': Categorical(['lsqr', 'eigen']),\n",
        "#                'shrinkage': Real(0, 1, prior='uniform'),\n",
        "#                'tol': Real(1e-6, 1e-4, prior='log-uniform')}},\n",
        "#\n",
        "#    'et': {'model': ExtraTreesClassifier(),\n",
        "#           'params': {\n",
        "#               'n_estimators': Integer(10, 500),\n",
        "#               'criterion': Categorical(['gini', 'entropy']),\n",
        "#               'max_depth': Integer(3, 30),\n",
        "#               'min_samples_split': Integer(2, 10),\n",
        "#               'min_samples_leaf': Integer(1, 10),\n",
        "#               'max_features': Real(0.1, 1.0, prior='uniform'),\n",
        "#               'bootstrap': Categorical([True, False]),\n",
        "#               'class_weight': Categorical(['balanced', 'balanced_subsample', None])}},\n",
        "\n",
        "#    'xgboost': {'model': XGBClassifier(),\n",
        "#                'params': {\n",
        "#                    'learning_rate': Real(0.01, 0.3, prior='uniform'),\n",
        "#                    'n_estimators': Integer(50, 500),\n",
        "#                    'max_depth': Integer(3, 10),\n",
        "#                    'min_child_weight': Integer(1, 10),\n",
        "#                    'gamma': Real(0, 1, prior='uniform'),\n",
        "#                    'subsample': Real(0.5, 1, prior='uniform'),\n",
        "#                    'colsample_bytree': Real(0.5, 1, prior='uniform'),\n",
        "#                    'reg_alpha': Real(0, 1, prior='uniform'),\n",
        "#                    'reg_lambda': Real(1, 3, prior='uniform'),\n",
        "#                    'scale_pos_weight': Real(1, 5, prior='uniform')}},\n",
        "#\n",
        "#    'lightgbm': {'model': LGBMClassifier(verbose=-1),\n",
        "#                 'params': {\n",
        "#                     'learning_rate': Real(1e-3, 1, prior='log-uniform'),\n",
        "#                     'n_estimators': Integer(10, 500),\n",
        "#                     'num_leaves': Integer(2, 100),\n",
        "#                     'max_depth': Integer(3, 10),\n",
        "#                     'min_child_samples': Integer(1, 50),\n",
        "#                     'min_child_weight': Real(1e-5, 1e-3, prior='log-uniform'),\n",
        "#                     'subsample': Real(0.1, 1.0, prior='uniform'),\n",
        "#                     'colsample_bytree': Real(0.1, 1.0, prior='uniform'),\n",
        "#                     'reg_alpha': Real(0, 1, prior='uniform'),\n",
        "#                     'reg_lambda': Real(0, 1, prior='uniform')}},\n",
        "#\n",
        "#    'catboost': {'model': CatBoostClassifier(verbose=0),\n",
        "#                 'params': {\n",
        "#                     'learning_rate': Real(1e-3, 1, prior='log-uniform'),\n",
        "#                     'iterations': Integer(10, 500),\n",
        "#                     'depth': Integer(3, 10),\n",
        "#                     'l2_leaf_reg': Real(1, 10, prior='uniform'),\n",
        "#                     'border_count': Integer(1, 255),\n",
        "#                     'bagging_temperature': Real(0, 1, prior='uniform'),\n",
        "#                     'random_strength': Real(1e-9, 10, prior='log-uniform')}}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVN85hSKal2Y"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "\n",
        "# Ignorar FutureWarning\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "# Ignorar ConvergenceWarning\n",
        "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
        "\n",
        "#lista para armazenar a referencia das threads\n",
        "threads = []\n",
        "\n",
        "# create a thread pool with max worker threads\n",
        "pool = ThreadPoolExecutor(max_workers=6)\n",
        "\n",
        "for model_name, mp in model_params.items():\n",
        "\n",
        "    # adiciona experimento na lista de threads: pool\n",
        "    exp = pool.submit(experiment, model_name, mp['model'],mp['params'], X_, y) # does not block\n",
        "\n",
        "    #adiciona na lista para salvar a referencia da thread\n",
        "    threads.append(exp)\n",
        "    time.sleep(0.1)\n",
        "\n",
        "# aguarda pela finalização das threads\n",
        "for exp in as_completed(threads):\n",
        "    exp.result()\n",
        "\n",
        "# fecha o pool\n",
        "pool.shutdown"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}