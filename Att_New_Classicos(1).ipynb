{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4OBYQFjS6gjp",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "574ec028-57c7-4083-d87b-2d962939adee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.0\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.7)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-24.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-24.7.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-24.7.0 scikit-optimize-0.10.2\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.22.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.13.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "#Install\n",
        "!pip install catboost\n",
        "!pip install xlsxwriter\n",
        "!pip install catboost\n",
        "!pip install scikit-optimize\n",
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu_FxriZl1lp",
        "outputId": "521744c6-02c1-4501-c92d-6349261660fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4jfPcmI79eIT",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad75386-2547-459f-dd0c-1b8f2eabd462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import *\n",
        "from threading import Thread\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from csv import writer\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from concurrent.futures import as_completed\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import csv\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
        "from openpyxl import Workbook\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from sklearn.exceptions import ConvergenceWarning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IVHUIdV3gaz",
        "outputId": "c956f2f2-faa8-44ac-a4c1-3ac5d6fd58cf",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "                                   \n",
            "-----------------------------------\n",
            "                                   \n",
            "Data shape: (50, 1570)\n",
            "Labels shape: (50,)\n",
            "Class names: ['Adamite' 'Aegirine' 'Aenigmatite' 'Akermanite' 'Amesite']\n",
            "                                   \n",
            "-----------------------------------\n",
            "                                   \n"
          ]
        }
      ],
      "source": [
        "def load_spectrum_file(dir_path, max_subfolders=None, max_files_per_subdir=None, max_rows=None):\n",
        "    \"\"\"Carrega arquivos de espectro e associa rótulos numéricos às subpastas.\"\"\"\n",
        "    data, labels = [], []\n",
        "    subfolder_labels = {}\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    # Contadores para controlar a quantidade de subpastas e arquivos lidos\n",
        "    subfolder_count = 0\n",
        "\n",
        "    for root, dirs, files in os.walk(dir_path):\n",
        "        # Limitar a quantidade de subpastas\n",
        "        if max_subfolders is not None and subfolder_count >= max_subfolders:\n",
        "            break\n",
        "\n",
        "        for dir_name in dirs:\n",
        "            subfolder_path = os.path.join(root, dir_name)\n",
        "            subfolder_labels[subfolder_path] = dir_name\n",
        "            subfolder_count += 1\n",
        "\n",
        "            # Limitar a quantidade de subpastas\n",
        "            if max_subfolders is not None and subfolder_count > max_subfolders:\n",
        "                break\n",
        "\n",
        "            file_count = 0\n",
        "            for filename in os.listdir(subfolder_path):\n",
        "                if filename.endswith('.csv'):\n",
        "                    if max_files_per_subdir is not None and file_count >= max_files_per_subdir:\n",
        "                        break\n",
        "                    file_path = os.path.join(subfolder_path, filename)\n",
        "                    try:\n",
        "                        df = pd.read_csv(file_path, delimiter=',', nrows=max_rows)\n",
        "                        y = df.iloc[:, 1].values  # Pega os valores da segunda coluna\n",
        "\n",
        "                        # Adiciona o rótulo da subpasta à lista de labels\n",
        "                        labels.append(subfolder_labels[subfolder_path])\n",
        "                        data.append(y)\n",
        "                        file_count += 1\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error reading file {file_path}: {e}\")\n",
        "\n",
        "    # Transforma os rótulos das subpastas em números\n",
        "    labels = label_encoder.fit_transform(labels)\n",
        "    return np.array(data), np.array(labels), label_encoder.classes_\n",
        "\n",
        "# Exemplo de uso\n",
        "print(\"Loading data...\")\n",
        "data, labels, class_names = load_spectrum_file(\n",
        "    '/content/drive/MyDrive/Iniciação Científica 2023-2024/PQ_TCC_IC/Raman/Data_csv/',\n",
        "    max_subfolders=5,\n",
        "    max_files_per_subdir=10,\n",
        "    max_rows=None\n",
        ")\n",
        "print(\"                                   \")\n",
        "print(\"-----------------------------------\")\n",
        "print(\"                                   \")\n",
        "print(f\"Data shape: {data.shape}\")\n",
        "print(f\"Labels shape: {labels.shape}\")\n",
        "print(f\"Class names: {class_names}\")\n",
        "print(\"                                   \")\n",
        "print(\"-----------------------------------\")\n",
        "print(\"                                   \")\n",
        "\n",
        "X_=data\n",
        "#print(X_)\n",
        "y=labels\n",
        "#X_ = np.nan_to_num(data)  # Substitui NaN e inf por zero\n",
        "\n",
        "#print(X_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [],
        "id": "lQV8yvGwp9K8"
      },
      "outputs": [],
      "source": [
        "# Definição do experimento\n",
        "def experiment(model_name, model, params, X_train, X_test, y_train, y_test, repet):\n",
        "    # Caminho da pasta para salvar o arquivo (cria uma pasta para cada modelo)\n",
        "    model_dir = os.path.join('Results/', model_name)\n",
        "\n",
        "    # Verifica se o diretório existe, se não, cria o diretório\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "\n",
        "    # Nome do arquivo para salvar os resultados\n",
        "    results_file = os.path.join(model_dir, f'{model_name}_repetição_{repet}.csv')\n",
        "\n",
        "    # configure the cross-validation procedure\n",
        "    cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "\n",
        "    # define search\n",
        "    search = BayesSearchCV(model, params, scoring='accuracy', cv=cv_inner, n_iter=5, refit=True, random_state=1, n_jobs=1)\n",
        "\n",
        "    # execute search\n",
        "    result = search.fit(X_train, y_train)\n",
        "\n",
        "    # get the best performing model fit on the whole training set\n",
        "    best_model = result.best_estimator_\n",
        "\n",
        "    # evaluate model on the hold out dataset\n",
        "    yhat = best_model.predict(X_test)\n",
        "\n",
        "    # evaluate the model\n",
        "    acc = accuracy_score(y_test, yhat)\n",
        "    prec = precision_score(y_test, yhat, average='weighted', zero_division=1)\n",
        "    rec = recall_score(y_test, yhat, average='weighted')\n",
        "    f1 = f1_score(y_test, yhat, average='weighted')\n",
        "    mcc = matthews_corrcoef(y_test, yhat)\n",
        "\n",
        "    # store the result\n",
        "    results = [[model_name, acc, rec, prec, f1, result.best_score_, result.best_params_]]\n",
        "\n",
        "    # report progress\n",
        "    print(f\"Repetição {repet}: {model_name} > acc={acc:.3f}, est={result.best_score_:.3f}, cfg={result.best_params_}\")\n",
        "\n",
        "    # save results to CSV, each repetition in a new file\n",
        "    df = pd.DataFrame(results, columns=['model', 'acc', 'rec', 'prec', 'f1', 'best_score', 'best_params'])\n",
        "    df.to_csv(results_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sk6gsx945YZK",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model_params = {\n",
        "          'lr': {'model': LogisticRegression(),\n",
        "                'params': {\n",
        "                            'C': Real(1e-4, 1e4, prior='log-uniform'),\n",
        "                            'fit_intercept': Categorical([True, False]),\n",
        "                            'solver': Categorical(['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),\n",
        "                            'max_iter':[500],\n",
        "                            'random_state': [1]}},\n",
        "\n",
        "          'knn': {'model': KNeighborsClassifier(),\n",
        "                  'params': {\n",
        "                            'n_neighbors': Integer(1, 50),\n",
        "                            'weights': Categorical(['uniform', 'distance']),\n",
        "                            'algorithm': Categorical(['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
        "                            'p': Integer(1, 5)}},\n",
        "\n",
        "          'nb': {'model': GaussianNB(),\n",
        "                'params': {\n",
        "                         'var_smoothing': Real(1e-10, 1e-1, prior='log-uniform')}},\n",
        "\n",
        "          'dt': {'model': DecisionTreeClassifier(),\n",
        "                'params': {\n",
        "                            'criterion': Categorical(['gini', 'entropy']),\n",
        "                            'splitter': Categorical(['best', 'random']),\n",
        "                            'max_depth': Integer(3, 30),\n",
        "                            'min_samples_split': Integer(2, 10),\n",
        "                            'min_samples_leaf': Integer(1, 10),\n",
        "                            'max_features': Real(0.1, 1.0, prior='uniform'),\n",
        "                            'random_state': [1]}},\n",
        "\n",
        "          'svm': {'model': SVC(),\n",
        "                  'params': {\n",
        "                            'C': Real(2**-5, 2**5, prior='log-uniform'),\n",
        "                            'kernel': Categorical(['linear', 'poly', 'rbf', 'sigmoid']),\n",
        "                            'degree': Integer(2, 5),  # Somente relevante para o kernel 'poly'\n",
        "                            'coef0': Real(0, 1),      # Relevante para os kernels 'poly' e 'sigmoid'\n",
        "                            'gamma': Real(2**-9, 2**1, prior='log-uniform'),\n",
        "                            'random_state': [1]}},\n",
        "\n",
        "          'gpc': {'model': GaussianProcessClassifier(),\n",
        "                  'params': {\n",
        "                            'optimizer': Categorical(['fmin_l_bfgs_b', None]),\n",
        "                            'n_restarts_optimizer': Integer(0, 10),\n",
        "                            'max_iter_predict': [500],\n",
        "                            'random_state': [1]}},\n",
        "\n",
        "          'mlp': {'model': MLPClassifier(),\n",
        "                  'params': {\n",
        "                            'hidden_layer_sizes': Integer(10,100),\n",
        "                            'activation': Categorical(['logistic', 'tanh', 'relu']),\n",
        "                            'solver': Categorical(['sgd', 'adam']),\n",
        "                            'max_iter': [5000],\n",
        "                            'random_state': [1]}},\n",
        "\n",
        "          'ridge': {'model': RidgeClassifier(),\n",
        "                    'params': {\n",
        "                                'alpha': Real(1e-4, 1e4, prior='log-uniform'),\n",
        "                                'fit_intercept': Categorical([True, False]),\n",
        "                                'solver': Categorical(['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']),\n",
        "                                'random_state': [1]}},\n",
        "\n",
        "          'rf': {'model': RandomForestClassifier(),\n",
        "                'params': {\n",
        "                          'n_estimators': Integer(10, 500),\n",
        "                          'criterion': Categorical(['gini', 'entropy']),\n",
        "                        'max_depth': Integer(3, 30),\n",
        "                          'random_state': [1]}},\n",
        "\n",
        "          'qda': {'model': QuadraticDiscriminantAnalysis(),\n",
        "                  'params': {\n",
        "                            'reg_param': Real(0, 1, prior='uniform'),\n",
        "                            'store_covariance': Categorical([True, False]),\n",
        "                            'tol': Real(1e-5, 1e-1, prior='log-uniform')}},\n",
        "\n",
        "          'ada': {'model': AdaBoostClassifier(),\n",
        "                  'params': {\n",
        "                            'n_estimators': Integer(10, 500),\n",
        "                            'learning_rate': Real(1e-3, 1, prior='log-uniform'),\n",
        "                           'algorithm': Categorical(['SAMME', 'SAMME.R']),\n",
        "                           'random_state': [1]}},\n",
        "\n",
        "         'lda': {'model': LinearDiscriminantAnalysis(),\n",
        "                 'params': {\n",
        "                        'solver': Categorical(['lsqr', 'eigen', 'auto']),\n",
        "                        'shrinkage': Real(0, 1, prior='uniform'),\n",
        "                        'tol': Real(1e-6, 1e-4, prior='log-uniform')}},\n",
        "\n",
        "          'et': {'model': ExtraTreesClassifier(),\n",
        "                 'params': {\n",
        "                         'n_estimators': Integer(10, 500),\n",
        "                         'criterion': Categorical(['gini', 'entropy']),\n",
        "                         'max_depth': Integer(3, 30)}},\n",
        "\n",
        "          'xgboost': {'model': XGBClassifier(),\n",
        "                      'params': {\n",
        "                                'learning_rate': Real(0.01, 0.3, prior='uniform'),\n",
        "                                'n_estimators': Integer(50, 500),\n",
        "                                'max_depth': Integer(3, 10),\n",
        "                                'gamma': Real(0, 1, prior='uniform'),\n",
        "                                }},\n",
        "\n",
        "          'lightgbm': {'model': LGBMClassifier(verbose=-1),\n",
        "                      'params': {\n",
        "                                'learning_rate': Real(1e-3, 1, prior='log-uniform'),\n",
        "                                'n_estimators': Integer(10, 500),\n",
        "                                'num_leaves': Integer(2, 100),\n",
        "                                'max_depth': Integer(3, 10)}},\n",
        "\n",
        "          'catboost': {'model': CatBoostClassifier(verbose=0),\n",
        "                     'params': {\n",
        "                               'learning_rate': Real(1e-3, 1, prior='log-uniform'),\n",
        "                               'iterations': Integer(10, 500),\n",
        "                               'depth': Integer(3, 10),\n",
        "                               'l2_leaf_reg': Real(1, 10, prior='uniform'),\n",
        "                               'border_count': Integer(1, 255),\n",
        "                               'bagging_temperature': Real(0, 1, prior='uniform'),\n",
        "                               'random_strength': Real(1e-9, 10, prior='log-uniform')}}\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "01Fr13kQp9LA",
        "outputId": "5b591779-f52d-44bc-fe85-c418f35cf6e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repetição 1: nb > acc=0.867, est=1.000, cfg=OrderedDict([('var_smoothing', 0.00021076812497703017)])\n",
            "Repetição 1: dt > acc=0.867, est=0.859, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 3), ('max_features', 0.7928811003072659), ('min_samples_leaf', 4), ('min_samples_split', 6), ('random_state', 1), ('splitter', 'random')])\n",
            "Repetição 1: knn > acc=1.000, est=1.000, cfg=OrderedDict([('algorithm', 'kd_tree'), ('n_neighbors', 4), ('p', 3), ('weights', 'uniform')])\n",
            "Repetição 1: svm > acc=1.000, est=1.000, cfg=OrderedDict([('C', 3.5691348204101585), ('coef0', 0.33460654520108274), ('degree', 2), ('gamma', 0.039767951577658237), ('kernel', 'poly'), ('random_state', 1)])\n",
            "Repetição 1: lr > acc=1.000, est=1.000, cfg=OrderedDict([('C', 41.79842712265741), ('fit_intercept', True), ('max_iter', 500), ('random_state', 1), ('solver', 'liblinear')])\n",
            "Repetição 1: ridge > acc=1.000, est=1.000, cfg=OrderedDict([('alpha', 41.79842712265741), ('fit_intercept', True), ('random_state', 1), ('solver', 'svd')])\n",
            "Repetição 1: gpc > acc=1.000, est=1.000, cfg=OrderedDict([('max_iter_predict', 500), ('n_restarts_optimizer', 1), ('optimizer', 'fmin_l_bfgs_b'), ('random_state', 1)])\n",
            "Repetição 1: qda > acc=0.267, est=0.369, cfg=OrderedDict([('reg_param', 0.6835574398742915), ('store_covariance', True), ('tol', 1.311128406562766e-05)])\n",
            "Repetição 2: lda > acc=1.000, est=1.000, cfg=OrderedDict([('shrinkage', 0.702644992444359), ('solver', 'lsqr'), ('tol', 5.672620790508924e-06)])\n",
            "Repetição 2: ada > acc=1.000, est=1.000, cfg=OrderedDict([('algorithm', 'SAMME.R'), ('learning_rate', 0.0015309295131923618), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 1: lda > acc=1.000, est=1.000, cfg=OrderedDict([('shrinkage', 0.702644992444359), ('solver', 'lsqr'), ('tol', 5.672620790508924e-06)])\n",
            "Repetição 1: xgboost > acc=0.875, est=0.778, cfg=OrderedDict([('gamma', 0.8303990122072878), ('learning_rate', 0.013900224647647744), ('max_depth', 8), ('n_estimators', 176)])\n",
            "Repetição 2: lightgbm > acc=0.125, est=0.178, cfg=OrderedDict([('learning_rate', 0.12821386062062406), ('max_depth', 3), ('n_estimators', 195), ('num_leaves', 16)])\n",
            "Repetição 2: et > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195)])\n",
            "Repetição 3: lr > acc=1.000, est=1.000, cfg=OrderedDict([('C', 41.79842712265741), ('fit_intercept', True), ('max_iter', 500), ('random_state', 1), ('solver', 'liblinear')])\n",
            "Repetição 3: nb > acc=1.000, est=1.000, cfg=OrderedDict([('var_smoothing', 0.0029757134630289256)])\n",
            "Repetição 3: dt > acc=1.000, est=0.478, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('max_features', 0.43920268855647115), ('min_samples_leaf', 2), ('min_samples_split', 6), ('random_state', 1), ('splitter', 'best')])\n",
            "Repetição 3: svm > acc=1.000, est=0.944, cfg=OrderedDict([('C', 3.5691348204101585), ('coef0', 0.33460654520108274), ('degree', 2), ('gamma', 0.039767951577658237), ('kernel', 'poly'), ('random_state', 1)])\n",
            "Repetição 1: rf > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 3: gpc > acc=1.000, est=1.000, cfg=OrderedDict([('max_iter_predict', 500), ('n_restarts_optimizer', 1), ('optimizer', 'fmin_l_bfgs_b'), ('random_state', 1)])\n",
            "Repetição 1: et > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195)])\n",
            "Repetição 1: lightgbm > acc=0.200, est=0.172, cfg=OrderedDict([('learning_rate', 0.12821386062062406), ('max_depth', 3), ('n_estimators', 195), ('num_leaves', 16)])\n",
            "Repetição 2: xgboost > acc=0.875, est=0.778, cfg=OrderedDict([('gamma', 0.8303990122072878), ('learning_rate', 0.013900224647647744), ('max_depth', 8), ('n_estimators', 176)])\n",
            "Repetição 3: ridge > acc=1.000, est=1.000, cfg=OrderedDict([('alpha', 41.79842712265741), ('fit_intercept', True), ('random_state', 1), ('solver', 'svd')])\n",
            "Repetição 3: rf > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 3: qda > acc=0.250, est=0.178, cfg=OrderedDict([('reg_param', 0.702644992444359), ('store_covariance', True), ('tol', 0.0003217862663291412)])\n",
            "Repetição 1: ada > acc=1.000, est=1.000, cfg=OrderedDict([('algorithm', 'SAMME.R'), ('learning_rate', 0.0015309295131923618), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 1: xgboost > acc=0.467, est=0.742, cfg=OrderedDict([('gamma', 0.702644992444359), ('learning_rate', 0.027879002226124737), ('max_depth', 6), ('n_estimators', 116)])\n",
            "Repetição 2: lr > acc=1.000, est=1.000, cfg=OrderedDict([('C', 41.79842712265741), ('fit_intercept', True), ('max_iter', 500), ('random_state', 1), ('solver', 'liblinear')])\n",
            "Repetição 2: knn > acc=1.000, est=1.000, cfg=OrderedDict([('algorithm', 'kd_tree'), ('n_neighbors', 4), ('p', 3), ('weights', 'uniform')])\n",
            "Repetição 2: nb > acc=0.867, est=1.000, cfg=OrderedDict([('var_smoothing', 0.00021076812497703017)])\n",
            "Repetição 2: dt > acc=0.867, est=0.859, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 3), ('max_features', 0.7928811003072659), ('min_samples_leaf', 4), ('min_samples_split', 6), ('random_state', 1), ('splitter', 'random')])\n",
            "Repetição 2: svm > acc=1.000, est=1.000, cfg=OrderedDict([('C', 3.5691348204101585), ('coef0', 0.33460654520108274), ('degree', 2), ('gamma', 0.039767951577658237), ('kernel', 'poly'), ('random_state', 1)])\n",
            "Repetição 2: gpc > acc=1.000, est=1.000, cfg=OrderedDict([('max_iter_predict', 500), ('n_restarts_optimizer', 1), ('optimizer', 'fmin_l_bfgs_b'), ('random_state', 1)])\n",
            "Repetição 2: ridge > acc=1.000, est=1.000, cfg=OrderedDict([('alpha', 41.79842712265741), ('fit_intercept', True), ('random_state', 1), ('solver', 'svd')])\n",
            "Repetição 1: catboost > acc=1.000, est=1.000, cfg=OrderedDict([('bagging_temperature', 0.6835574398742915), ('border_count', 86), ('depth', 3), ('iterations', 223), ('l2_leaf_reg', 4.631078489530096), ('learning_rate', 0.1735056630016637), ('random_strength', 2.749734943636558e-09)])\n",
            "Repetição 2: rf > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 3: lda > acc=1.000, est=1.000, cfg=OrderedDict([('shrinkage', 0.702644992444359), ('solver', 'lsqr'), ('tol', 5.672620790508924e-06)])\n",
            "Repetição 2: qda > acc=0.267, est=0.369, cfg=OrderedDict([('reg_param', 0.6835574398742915), ('store_covariance', True), ('tol', 1.311128406562766e-05)])\n",
            "Repetição 3: ada > acc=1.000, est=1.000, cfg=OrderedDict([('algorithm', 'SAMME.R'), ('learning_rate', 0.0015309295131923618), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 3: et > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195)])\n",
            "Repetição 3: lightgbm > acc=0.125, est=0.178, cfg=OrderedDict([('learning_rate', 0.12821386062062406), ('max_depth', 3), ('n_estimators', 195), ('num_leaves', 16)])\n",
            "Repetição 3: xgboost > acc=0.875, est=0.778, cfg=OrderedDict([('gamma', 0.8303990122072878), ('learning_rate', 0.013900224647647744), ('max_depth', 8), ('n_estimators', 176)])\n",
            "Repetição 4: lr > acc=1.000, est=1.000, cfg=OrderedDict([('C', 41.79842712265741), ('fit_intercept', True), ('max_iter', 500), ('random_state', 1), ('solver', 'liblinear')])\n",
            "Repetição 4: nb > acc=1.000, est=1.000, cfg=OrderedDict([('var_smoothing', 0.0029757134630289256)])\n",
            "Repetição 4: dt > acc=1.000, est=0.478, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('max_features', 0.43920268855647115), ('min_samples_leaf', 2), ('min_samples_split', 6), ('random_state', 1), ('splitter', 'best')])\n",
            "Repetição 4: svm > acc=1.000, est=0.944, cfg=OrderedDict([('C', 3.5691348204101585), ('coef0', 0.33460654520108274), ('degree', 2), ('gamma', 0.039767951577658237), ('kernel', 'poly'), ('random_state', 1)])\n",
            "Repetição 4: gpc > acc=1.000, est=1.000, cfg=OrderedDict([('max_iter_predict', 500), ('n_restarts_optimizer', 1), ('optimizer', 'fmin_l_bfgs_b'), ('random_state', 1)])\n",
            "Repetição 1: mlp > acc=1.000, est=1.000, cfg=OrderedDict([('activation', 'relu'), ('hidden_layer_sizes', 16), ('max_iter', 5000), ('random_state', 1), ('solver', 'sgd')])\n",
            "Repetição 3: mlp > acc=1.000, est=1.000, cfg=OrderedDict([('activation', 'relu'), ('hidden_layer_sizes', 16), ('max_iter', 5000), ('random_state', 1), ('solver', 'sgd')])\n",
            "Repetição 4: ridge > acc=1.000, est=1.000, cfg=OrderedDict([('alpha', 41.79842712265741), ('fit_intercept', True), ('random_state', 1), ('solver', 'svd')])\n",
            "Repetição 2: lda > acc=1.000, est=1.000, cfg=OrderedDict([('shrinkage', 0.702644992444359), ('solver', 'lsqr'), ('tol', 5.672620790508924e-06)])\n",
            "Repetição 2: et > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195)])\n",
            "Repetição 2: ada > acc=1.000, est=1.000, cfg=OrderedDict([('algorithm', 'SAMME.R'), ('learning_rate', 0.0015309295131923618), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 2: lightgbm > acc=0.200, est=0.172, cfg=OrderedDict([('learning_rate', 0.12821386062062406), ('max_depth', 3), ('n_estimators', 195), ('num_leaves', 16)])\n",
            "Repetição 4: rf > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 4: qda > acc=0.250, est=0.178, cfg=OrderedDict([('reg_param', 0.702644992444359), ('store_covariance', True), ('tol', 0.0003217862663291412)])\n",
            "Repetição 2: xgboost > acc=0.467, est=0.742, cfg=OrderedDict([('gamma', 0.702644992444359), ('learning_rate', 0.027879002226124737), ('max_depth', 6), ('n_estimators', 116)])\n",
            "Repetição 2: mlp > acc=1.000, est=1.000, cfg=OrderedDict([('activation', 'relu'), ('hidden_layer_sizes', 16), ('max_iter', 5000), ('random_state', 1), ('solver', 'sgd')])\n",
            "Repetição 3: lr > acc=1.000, est=1.000, cfg=OrderedDict([('C', 41.79842712265741), ('fit_intercept', True), ('max_iter', 500), ('random_state', 1), ('solver', 'liblinear')])\n",
            "Repetição 3: knn > acc=1.000, est=1.000, cfg=OrderedDict([('algorithm', 'kd_tree'), ('n_neighbors', 4), ('p', 3), ('weights', 'uniform')])\n",
            "Repetição 3: nb > acc=0.867, est=1.000, cfg=OrderedDict([('var_smoothing', 0.00021076812497703017)])\n",
            "Repetição 3: dt > acc=0.867, est=0.859, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 3), ('max_features', 0.7928811003072659), ('min_samples_leaf', 4), ('min_samples_split', 6), ('random_state', 1), ('splitter', 'random')])\n",
            "Repetição 3: svm > acc=1.000, est=1.000, cfg=OrderedDict([('C', 3.5691348204101585), ('coef0', 0.33460654520108274), ('degree', 2), ('gamma', 0.039767951577658237), ('kernel', 'poly'), ('random_state', 1)])\n",
            "Repetição 3: gpc > acc=1.000, est=1.000, cfg=OrderedDict([('max_iter_predict', 500), ('n_restarts_optimizer', 1), ('optimizer', 'fmin_l_bfgs_b'), ('random_state', 1)])\n",
            "Repetição 4: ada > acc=1.000, est=1.000, cfg=OrderedDict([('algorithm', 'SAMME.R'), ('learning_rate', 0.0015309295131923618), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 3: ridge > acc=1.000, est=1.000, cfg=OrderedDict([('alpha', 41.79842712265741), ('fit_intercept', True), ('random_state', 1), ('solver', 'svd')])\n",
            "Repetição 4: lda > acc=1.000, est=1.000, cfg=OrderedDict([('shrinkage', 0.702644992444359), ('solver', 'lsqr'), ('tol', 5.672620790508924e-06)])\n",
            "Repetição 4: mlp > acc=1.000, est=1.000, cfg=OrderedDict([('activation', 'relu'), ('hidden_layer_sizes', 16), ('max_iter', 5000), ('random_state', 1), ('solver', 'sgd')])\n",
            "Repetição 3: rf > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 4: et > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195)])\n",
            "Repetição 3: qda > acc=0.267, est=0.369, cfg=OrderedDict([('reg_param', 0.6835574398742915), ('store_covariance', True), ('tol', 1.311128406562766e-05)])\n",
            "Repetição 4: lightgbm > acc=0.125, est=0.178, cfg=OrderedDict([('learning_rate', 0.12821386062062406), ('max_depth', 3), ('n_estimators', 195), ('num_leaves', 16)])\n",
            "Repetição 2: catboost > acc=1.000, est=1.000, cfg=OrderedDict([('bagging_temperature', 0.6835574398742915), ('border_count', 86), ('depth', 3), ('iterations', 223), ('l2_leaf_reg', 4.631078489530096), ('learning_rate', 0.1735056630016637), ('random_strength', 2.749734943636558e-09)])\n",
            "Repetição 5: lr > acc=1.000, est=1.000, cfg=OrderedDict([('C', 41.79842712265741), ('fit_intercept', True), ('max_iter', 500), ('random_state', 1), ('solver', 'liblinear')])\n",
            "Repetição 5: nb > acc=1.000, est=1.000, cfg=OrderedDict([('var_smoothing', 0.0029757134630289256)])\n",
            "Repetição 5: dt > acc=1.000, est=0.478, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('max_features', 0.43920268855647115), ('min_samples_leaf', 2), ('min_samples_split', 6), ('random_state', 1), ('splitter', 'best')])\n",
            "Repetição 5: svm > acc=1.000, est=0.944, cfg=OrderedDict([('C', 3.5691348204101585), ('coef0', 0.33460654520108274), ('degree', 2), ('gamma', 0.039767951577658237), ('kernel', 'poly'), ('random_state', 1)])\n",
            "Repetição 4: xgboost > acc=0.875, est=0.778, cfg=OrderedDict([('gamma', 0.8303990122072878), ('learning_rate', 0.013900224647647744), ('max_depth', 8), ('n_estimators', 176)])\n",
            "Repetição 5: gpc > acc=1.000, est=1.000, cfg=OrderedDict([('max_iter_predict', 500), ('n_restarts_optimizer', 1), ('optimizer', 'fmin_l_bfgs_b'), ('random_state', 1)])\n",
            "Repetição 5: ridge > acc=1.000, est=1.000, cfg=OrderedDict([('alpha', 41.79842712265741), ('fit_intercept', True), ('random_state', 1), ('solver', 'svd')])\n",
            "Repetição 5: rf > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 5: qda > acc=0.250, est=0.178, cfg=OrderedDict([('reg_param', 0.702644992444359), ('store_covariance', True), ('tol', 0.0003217862663291412)])\n",
            "Repetição 3: ada > acc=1.000, est=1.000, cfg=OrderedDict([('algorithm', 'SAMME.R'), ('learning_rate', 0.0015309295131923618), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 3: mlp > acc=1.000, est=1.000, cfg=OrderedDict([('activation', 'relu'), ('hidden_layer_sizes', 16), ('max_iter', 5000), ('random_state', 1), ('solver', 'sgd')])\n",
            "Repetição 3: lda > acc=1.000, est=1.000, cfg=OrderedDict([('shrinkage', 0.702644992444359), ('solver', 'lsqr'), ('tol', 5.672620790508924e-06)])\n",
            "Repetição 5: ada > acc=1.000, est=1.000, cfg=OrderedDict([('algorithm', 'SAMME.R'), ('learning_rate', 0.0015309295131923618), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 1: catboost > acc=1.000, est=1.000, cfg=OrderedDict([('bagging_temperature', 0.702644992444359), ('border_count', 17), ('depth', 6), ('iterations', 81), ('l2_leaf_reg', 5.438579263598313), ('learning_rate', 0.46427597949847466), ('random_strength', 3.8447832291713815e-09)])\n",
            "Repetição 3: et > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195)])\n",
            "Repetição 3: lightgbm > acc=0.200, est=0.172, cfg=OrderedDict([('learning_rate', 0.12821386062062406), ('max_depth', 3), ('n_estimators', 195), ('num_leaves', 16)])\n",
            "Repetição 4: lr > acc=1.000, est=1.000, cfg=OrderedDict([('C', 41.79842712265741), ('fit_intercept', True), ('max_iter', 500), ('random_state', 1), ('solver', 'liblinear')])\n",
            "Repetição 4: knn > acc=1.000, est=1.000, cfg=OrderedDict([('algorithm', 'kd_tree'), ('n_neighbors', 4), ('p', 3), ('weights', 'uniform')])\n",
            "Repetição 4: nb > acc=0.867, est=1.000, cfg=OrderedDict([('var_smoothing', 0.00021076812497703017)])\n",
            "Repetição 4: dt > acc=0.867, est=0.859, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 3), ('max_features', 0.7928811003072659), ('min_samples_leaf', 4), ('min_samples_split', 6), ('random_state', 1), ('splitter', 'random')])\n",
            "Repetição 4: svm > acc=1.000, est=1.000, cfg=OrderedDict([('C', 3.5691348204101585), ('coef0', 0.33460654520108274), ('degree', 2), ('gamma', 0.039767951577658237), ('kernel', 'poly'), ('random_state', 1)])\n",
            "Repetição 4: gpc > acc=1.000, est=1.000, cfg=OrderedDict([('max_iter_predict', 500), ('n_restarts_optimizer', 1), ('optimizer', 'fmin_l_bfgs_b'), ('random_state', 1)])\n",
            "Repetição 5: lda > acc=1.000, est=1.000, cfg=OrderedDict([('shrinkage', 0.702644992444359), ('solver', 'lsqr'), ('tol', 5.672620790508924e-06)])\n",
            "Repetição 5: mlp > acc=1.000, est=1.000, cfg=OrderedDict([('activation', 'relu'), ('hidden_layer_sizes', 16), ('max_iter', 5000), ('random_state', 1), ('solver', 'sgd')])\n",
            "Repetição 5: et > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195)])\n",
            "Repetição 5: lightgbm > acc=0.125, est=0.178, cfg=OrderedDict([('learning_rate', 0.12821386062062406), ('max_depth', 3), ('n_estimators', 195), ('num_leaves', 16)])\n",
            "Repetição 3: catboost > acc=1.000, est=1.000, cfg=OrderedDict([('bagging_temperature', 0.6835574398742915), ('border_count', 86), ('depth', 3), ('iterations', 223), ('l2_leaf_reg', 4.631078489530096), ('learning_rate', 0.1735056630016637), ('random_strength', 2.749734943636558e-09)])\n",
            "Repetição 3: xgboost > acc=0.467, est=0.742, cfg=OrderedDict([('gamma', 0.702644992444359), ('learning_rate', 0.027879002226124737), ('max_depth', 6), ('n_estimators', 116)])\n",
            "Repetição 6: lr > acc=1.000, est=1.000, cfg=OrderedDict([('C', 41.79842712265741), ('fit_intercept', True), ('max_iter', 500), ('random_state', 1), ('solver', 'liblinear')])\n",
            "Repetição 6: nb > acc=1.000, est=1.000, cfg=OrderedDict([('var_smoothing', 0.0029757134630289256)])\n",
            "Repetição 4: ridge > acc=1.000, est=1.000, cfg=OrderedDict([('alpha', 41.79842712265741), ('fit_intercept', True), ('random_state', 1), ('solver', 'svd')])\n",
            "Repetição 6: dt > acc=1.000, est=0.478, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('max_features', 0.43920268855647115), ('min_samples_leaf', 2), ('min_samples_split', 6), ('random_state', 1), ('splitter', 'best')])\n",
            "Repetição 6: svm > acc=1.000, est=0.944, cfg=OrderedDict([('C', 3.5691348204101585), ('coef0', 0.33460654520108274), ('degree', 2), ('gamma', 0.039767951577658237), ('kernel', 'poly'), ('random_state', 1)])\n",
            "Repetição 6: gpc > acc=1.000, est=1.000, cfg=OrderedDict([('max_iter_predict', 500), ('n_restarts_optimizer', 1), ('optimizer', 'fmin_l_bfgs_b'), ('random_state', 1)])\n",
            "Repetição 5: xgboost > acc=0.875, est=0.778, cfg=OrderedDict([('gamma', 0.8303990122072878), ('learning_rate', 0.013900224647647744), ('max_depth', 8), ('n_estimators', 176)])\n",
            "Repetição 6: ridge > acc=1.000, est=1.000, cfg=OrderedDict([('alpha', 41.79842712265741), ('fit_intercept', True), ('random_state', 1), ('solver', 'svd')])\n",
            "Repetição 4: rf > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 4: qda > acc=0.267, est=0.369, cfg=OrderedDict([('reg_param', 0.6835574398742915), ('store_covariance', True), ('tol', 1.311128406562766e-05)])\n",
            "Repetição 6: rf > acc=1.000, est=1.000, cfg=OrderedDict([('criterion', 'entropy'), ('max_depth', 5), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 6: qda > acc=0.250, est=0.178, cfg=OrderedDict([('reg_param', 0.702644992444359), ('store_covariance', True), ('tol', 0.0003217862663291412)])\n",
            "Repetição 4: mlp > acc=1.000, est=1.000, cfg=OrderedDict([('activation', 'relu'), ('hidden_layer_sizes', 16), ('max_iter', 5000), ('random_state', 1), ('solver', 'sgd')])\n",
            "Repetição 6: ada > acc=1.000, est=1.000, cfg=OrderedDict([('algorithm', 'SAMME.R'), ('learning_rate', 0.0015309295131923618), ('n_estimators', 195), ('random_state', 1)])\n",
            "Repetição 4: lda > acc=1.000, est=1.000, cfg=OrderedDict([('shrinkage', 0.702644992444359), ('solver', 'lsqr'), ('tol', 5.672620790508924e-06)])\n"
          ]
        }
      ],
      "source": [
        "# Loop para realizar 30 iterações de train_test_split e executar experimentos\n",
        "\n",
        "# Lista para armazenar a referência das threads\n",
        "threads = []\n",
        "\n",
        "# Cria o pool de threads\n",
        "pool = ThreadPoolExecutor(max_workers=4)\n",
        "\n",
        "for i in range(30):\n",
        "    # Realiza o particionamento dos dados\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_, y, train_size=0.7, test_size=0.3, random_state=1, shuffle=True, stratify=y)\n",
        "\n",
        "    for model_name, mp in model_params.items():\n",
        "        # Adiciona o experimento na lista de threads\n",
        "        exp = pool.submit(experiment, model_name, mp['model'], mp['params'], X_train, X_test, y_train, y_test, i + 1)\n",
        "\n",
        "        # Armazena a referência da thread\n",
        "        threads.append(exp)\n",
        "        time.sleep(0.1)\n",
        "\n",
        "    # Aguarda a finalização das threads\n",
        "for exp in as_completed(threads):\n",
        "    exp.result()\n",
        "\n",
        "# Fecha o pool\n",
        "#pool.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOmLqfZmp9LH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "conda-base-py",
      "name": "workbench-notebooks.m124",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}